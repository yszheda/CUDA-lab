<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Accelerate Reed-Solomon coding for Fault-Tolerance in RAID-like System</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.min.css">
		<link rel="stylesheet" href="css/theme/default.css" id="theme">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- For displaying theorems in LaTeX ways -->
		<link rel="stylesheet" href="css/theorems.css">

		<!-- For printing -->
		<link rel="stylesheet" href="css/print/pdf.css">

		<!-- If the query includes 'print-pdf', use the PDF print sheet -->
		<script>
			document.write( '<link rel="stylesheet" href="css/print/' + ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h1>CUDA Lab</h1>
					<p>
					<a href="lsalab.cs.nthu.edu.tw/home">LSALab</a>
					</p>
				</section>

				<section>
					<h2>Overview</h2>
					<ul>
						<li>CUDA Tools</li>
						<li>Information of Our GPU Devices</li>
						<li>Lab Tasks</li>
					</ul>

					<aside class="notes">
						Oh hey, these are some notes. They'll be hidden in your presentation, but you can see them if you open the speaker notes window (hit 's' on your keyboard).
					</aside>
				</section>

				<!-- Example of nested vertical slides -->
				<section>
					<section>
						<h2>CUDA Tools</h2>
						<p>
						</p>
					</section>
					<section>
						<h2>Compiler: nvcc</h2>
						<p>
						nvcc separates source code into host and device components:
						<ul>
							<li>
							Device functions are processed by NVIDIA compiler
							</li>
							<li>
							Host functions are processed by standard host compiler, such as gcc, clang.
							</li>
						</ul>
						</p>
					</section>
					<section>
						<h2>Compiler: nvcc</h2>
						<p>
						Usage (like gcc):
						<pre><code class="shell" data-trim>
# compile to object file (do not link)
$ nvcc -c a.cu -o a.o
						</code></pre>
						<pre><code class="shell" data-trim>
# compile to executable file
$ nvcc a.cu -o a.out
						</code></pre>
						<pre><code class="shell" data-trim>
# generate PTX intermediate assembly file
$ nvcc -ptx a.cu
						</code></pre>
						</p>
<!--						
						<p>
						Sample Makefile
						<pre><code class="cpp" data-trim>
NVCC = nvcc
CCFLAGS = 
NVCCFLAGS = 
LDFLAGS = 
SRCS = $(wildcard *.cu)
OBJS = $(patsubst %.cu, %.o, $(SRCS))
all:$(OBJS)
%.o: %.cu
        $(NVCC) -o $@ $< $(CCFLAGS) $(NVCCFLAGS) $(LDFLAGS)
clean:
        rm *.o
						</code></pre>
						</p>
-->						
					</section>
					<section>
						<h2>Compiler: nvcc</h2>
						<h2>Interesting Usages</h2>
						<p>
						Printing code generation statistics:
						<pre><code class="cpp" data-trim>
$ nvcc -Xptxas -v acos.cu
ptxas info   : Compiling entry function 'acos_main'
ptxas info   : Used 4 registers, 60+56 bytes lmem, 44+40 bytes smem, 
               20 bytes cmem[1], 12 bytes cmem[14]
						</code></pre>
						<pre><code class="shell" data-trim>
-Xptxas
--ptxas-options
	 Specify options directly to the ptx optimizing assembler.
						</code></pre>
						</p>
					<aside class="notes">
As shown in the above example, the amounts of local and shared memory are listed by two numbers each. First number represents the total size of all the variables declared in that memory segment and the second number represents the amount of system allocated data. The amount and location of system allocated data as well as the allocation of constant variables to constant banks is profile specific. For constant memory, the total space allocated in that bank is shown.
					</aside>

					</section>
					<section>
						<h2>cuda-memcheck</h2>
						<p>
						Recommended for checking errors of your program
<table summary="" id="supported-error-detection__memcheck-error-types" class="table" frame="border" border="1" rules="all" style="font-size: 16px">
                        <caption><span class="tablecap">Table . Memcheck reported error types</span></caption>
                        <thead class="thead" align="left">
                           <tr class="row">
                              <th class="entry" valign="top" id="d54e850" rowspan="1" colspan="1">Name</th>
                              <th class="entry" valign="top" id="d54e853" rowspan="1" colspan="1">Description</th>
                              <th class="entry" valign="top" id="d54e856" rowspan="1" colspan="1">Location</th>
                              <th class="entry" valign="top" id="d54e859" rowspan="1" colspan="1">Precision</th>
                             
                           </tr>
                        </thead>
                        <tbody class="tbody">
                           <tr class="row">
                              <td class="entry" valign="top" headers="d54e850" rowspan="1" colspan="1"><dfn class="term">Memory access error</dfn></td>
                              <td class="entry" valign="top" headers="d54e853" rowspan="1" colspan="1">
                                 Errors due to
                                 out of bounds or misaligned accesses to memory by a global,
                                 local, shared or global atomic access.
                                 
                              </td>
                              <td class="entry" valign="top" headers="d54e856" rowspan="1" colspan="1">Device</td>
                              <td class="entry" valign="top" headers="d54e859" rowspan="1" colspan="1">Precise</td>
                            
                           </tr>
                           <tr class="row">
                              <td class="entry" valign="top" headers="d54e850" rowspan="1" colspan="1"><dfn class="term">Hardware exception</dfn></td>
                              <td class="entry" valign="top" headers="d54e853" rowspan="1" colspan="1">
                                 Errors that are reported
                                 by the hardware error reporting mechanism.
                                 
                              </td>
                              <td class="entry" valign="top" headers="d54e856" rowspan="1" colspan="1">Device</td>
                              <td class="entry" valign="top" headers="d54e859" rowspan="1" colspan="1">Imprecise</td>
                           
                           </tr>
                           <tr class="row">
                              <td class="entry" valign="top" headers="d54e850" rowspan="1" colspan="1"><dfn class="term">Malloc/Free errors</dfn></td>
                              <td class="entry" valign="top" headers="d54e853" rowspan="1" colspan="1">
                                 Errors that occur due to incorrect
                                 use of <samp class="ph codeph">malloc()/free()</samp>
                                 in CUDA kernels.
                                 
                              </td>
                              <td class="entry" valign="top" headers="d54e856" rowspan="1" colspan="1">Device</td>
                              <td class="entry" valign="top" headers="d54e859" rowspan="1" colspan="1">Precise</td>

                           </tr>
                           <tr class="row">
                              <td class="entry" valign="top" headers="d54e850" rowspan="1" colspan="1"><dfn class="term">CUDA API errors</dfn></td>
                              <td class="entry" valign="top" headers="d54e853" rowspan="1" colspan="1">
                                 Reported when a CUDA API call in the application
                                 returns a failure.
                                 
                              </td>
                              <td class="entry" valign="top" headers="d54e856" rowspan="1" colspan="1">Host</td>
                              <td class="entry" valign="top" headers="d54e859" rowspan="1" colspan="1">Precise</td>
                          
                           </tr>
                           <tr class="row">
                              <td class="entry" valign="top" headers="d54e850" rowspan="1" colspan="1"><dfn class="term">cudaMalloc memory leaks</dfn></td>
                              <td class="entry" valign="top" headers="d54e853" rowspan="1" colspan="1">
                                 Allocations of device memory using <samp class="ph codeph">cudaMalloc()</samp>
                                 that have not been freed by the application.
                                 
                              </td>
                              <td class="entry" valign="top" headers="d54e856" rowspan="1" colspan="1">Host</td>
                              <td class="entry" valign="top" headers="d54e859" rowspan="1" colspan="1">Precise</td>
                         
                           </tr>
                           <tr class="row">
                              <td class="entry" valign="top" headers="d54e850" rowspan="1" colspan="1"><dfn class="term">Device Heap Memory Leaks</dfn></td>
                              <td class="entry" valign="top" headers="d54e853" rowspan="1" colspan="1">
                                 Allocations of device memory using <samp class="ph codeph">malloc()</samp>
                                 in device code that have not been freed by the application.
                                 
                              </td>
                              <td class="entry" valign="top" headers="d54e856" rowspan="1" colspan="1">Device</td>
                              <td class="entry" valign="top" headers="d54e859" rowspan="1" colspan="1">Imprecise</td>
                        
                           </tr>
                        </tbody>
                     </table>
						</p>
					</section>
					<section>
						<h2>cuda-memcheck</h2>
						<p>
						Usage:
						<pre><code class="shell" data-trim>
$ cuda-memcheck [executable-program]
						</code></pre>
						</p>
					</section>
					<section>
						<h2>nvidia-smi</h2>
						<p>
						NVIDIA System Management Interface: Query and modify GPU devices' state.
						</p>
						<p>
						Example:
						<pre><code class="shell" data-trim>
$ nvidia-smi
Wed Dec 25 08:16:21 2013       
+------------------------------------------------------+                       
| NVIDIA-SMI 5.319.37   Driver Version: 319.37         |                       
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K20Xm         On   | 0000:0B:00.0     Off |                    0 |
| N/A   35C    P0    60W / 235W |       84MB /  5759MB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K20Xm         On   | 0000:85:00.0     Off |                    0 |
| N/A   39C    P0    60W / 235W |       14MB /  5759MB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Compute processes:                                               GPU Memory |
|  GPU       PID  Process name                                     Usage      |
|=============================================================================|
|    0     33736  ./RS                                                  69MB  |
+-----------------------------------------------------------------------------+
						</code></pre>
						<pre><code class="shell" data-trim>
$ nvidia-smi -q -d [TEMPERATURE|MEMORY|POWER|CLOCK|...]
						</code></pre>
						</p>
					</section>
				</section>

				<section>
					<h2>Information of Our Devicies</h2>
					<p>
					You can execute the following command on our machine to obtain the detailed information:
					<pre><code class="shell" data-trim contenteditable>
$ /usr/local/cuda/samples/1_Utilities/deviceQuery/deviceQuery
					</code></pre>
					<pre><code class="text" data-trim>
Device 0: "Tesla K20Xm"
  CUDA Driver Version / Runtime Version          5.5 / 5.5
  CUDA Capability Major/Minor version number:    3.5
  Total amount of global memory:                 5760 MBytes (6039339008 bytes)
  (14) Multiprocessors, (192) CUDA Cores/MP:     2688 CUDA Cores
  GPU Clock rate:                                732 MHz (0.73 GHz)
  Memory Clock rate:                             2600 Mhz
  Memory Bus Width:                              384-bit
  L2 Cache Size:                                 1572864 bytes
  Total amount of constant memory:               65536 bytes
  Total amount of shared memory per block:       49152 bytes
  Total number of registers available per block: 65536
  Warp size:                                     32
  Maximum number of threads per multiprocessor:  2048
  Maximum number of threads per block:           1024
  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)
  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)
					</code></pre>
					</p>
					<aside class="notes">
CUDA cores, max block/grid size, shared mem
					</aside>
				</section>

				<section>
					<section>
						<h2>Our Tasks</h2>
						<p>
						<ul>
							<li>
							Rewrite the CPU sequential program into a CUDA program to increase each element of an array by one. The element number in this array is set to 1024.
							</li>
							<li>
							Implement four version of GPU parallel reduction algorithm to calculate the sum of an array. You will have to fill in a template CUDA program and test their performance.
							</li>
						</ul>
						</p>
					</section>
					<section>
						<h2>How to Measure Kernel Execution Time Using CUDA GPU Timers</h2>
						<p>
						<pre><code class="c" data-trim>
cudaEvent_t start, stop;
float time;

cudaEventCreate(&start);
cudaEventCreate(&stop);

cudaEventRecord( start, 0 );
kernel<<<grid,threads>>> (d_idata, d_odata);
cudaEventRecord( stop, 0 );
cudaEventSynchronize( stop );

cudaEventElapsedTime( &time, start, stop );
cudaEventDestroy( start );
cudaEventDestroy( stop );
						</code></pre>
						</p>
						<p>
						NOTE: The cudaEventElapsedTime() function returns the time elapsed between the recording of the start and stop events. This value is expressed in milliseconds.
						</p>
					</section>
				</section>

				<section>
					<h1>THE END</h1>
					<h3>Q & A</h3>
				</section>

			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.min.js"></script>

		<script>

			// Full list of configuration options available here:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
				transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

//				math: {
//				    mathjax: 'http://cdn.mathjax.org/mathjax/latest/MathJax.js',
//				    config: 'TeX-AMS_HTML-full'  // See http://docs.mathjax.org/en/latest/config-files.html
//				},

				// Optional libraries used to extend on reveal.js
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: 'plugin/math/math.js', async: true }
				]
			});

		</script>

	</body>
</html>
